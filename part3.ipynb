{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8525393,"sourceType":"datasetVersion","datasetId":5090931}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AutoTokenizer, BertForSequenceClassification, AdamW\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom nltk.translate.bleu_score import sentence_bleu\n\n\n# Initialize tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5).cuda()  # Assuming review scores range from 1 to 5\n","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:52:46.497762Z","iopub.execute_input":"2024-05-27T07:52:46.498706Z","iopub.status.idle":"2024-05-27T07:53:00.220937Z","shell.execute_reply.started":"2024-05-27T07:52:46.498671Z","shell.execute_reply":"2024-05-27T07:53:00.219982Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf5457fa76944002825badd269a8a23d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"209aafbbb6064f4e83bc35ba2fd4c8cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ab322a48962489c8d639a14b394c734"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d8fd564576948f2b95cb1fc1ce9db40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e88b1273fe4946e7b331589c784733dd"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def parse_reviews(lines):\n    reviews = []\n    review = {}\n    \n    for line in lines:\n        line = line.strip()\n        if line == '':  \n            if review:\n                reviews.append(review)\n                review = {}\n        else:\n            if ': ' in line:\n                key, value = line.split(': ', 1)\n                review[key] = value\n    \n    if review:\n        reviews.append(review)\n    \n    return reviews\n\nfile_path = '/kaggle/input/amazon/Beauty.txt'  \nwith open(file_path, 'r') as file:\n    lines = file.readlines()\n\nparsed_data = parse_reviews(lines)\ndf = pd.DataFrame(parsed_data)\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:53:00.222531Z","iopub.execute_input":"2024-05-27T07:53:00.223001Z","iopub.status.idle":"2024-05-27T07:53:05.355201Z","shell.execute_reply.started":"2024-05-27T07:53:00.222975Z","shell.execute_reply":"2024-05-27T07:53:05.354180Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"       product/productId                                      product/title  \\\n0             B00064C0IU  Oscar Eau de Toilette for Women by Oscar de La...   \n1             B00064C0IU  Oscar Eau de Toilette for Women by Oscar de La...   \n2             B00064C0IU  Oscar Eau de Toilette for Women by Oscar de La...   \n3             B00064C0IU  Oscar Eau de Toilette for Women by Oscar de La...   \n4             B000K5JBZU  Optimum Care Anti-Breakage Therapy Moisture Re...   \n...                  ...                                                ...   \n252051        B000FKGRSO  Artec Kiwi Coloreflector Shine Wax, 2-Ounce Ja...   \n252052        B00025X06E                 Goldleaf Perfumed Body Cream 230ml   \n252053        B00025X06E                 Goldleaf Perfumed Body Cream 230ml   \n252054        B000BR64OS                   Guerlain Vetiver Eau de Toilette   \n252055        B000BR64OS                   Guerlain Vetiver Eau de Toilette   \n\n       product/price   review/userId            review/profileName  \\\n0              24.19  A1FWT811DSZLC8                       Heidi M   \n1              24.19  A1THE6V6O8ROD4  Donna Mpaulin \"PURPLE RAVEN\"   \n2              24.19  A176IQ7MVD3N6T                      M. Avila   \n3              24.19  A34BDX4JVMG23Y                   Kim M. Colt   \n4               5.99  A3UWJXJI7S3T05                        PloveJ   \n...              ...             ...                           ...   \n252051       unknown   AGEYHIE3Y3NUR                     J. Hatten   \n252052         28.00  A3M174IC0VXOS2                    Gail Cooke   \n252053         28.00  A2SZ9BG00RYAHG               &#34;Janie&#34;   \n252054       unknown  A13NEK0V8EMHPO               PA Fishing Maps   \n252055       unknown   AAX3RFP8NWI1U                  Terry Grabow   \n\n       review/helpfulness review/score review/time  \\\n0                     0/0          3.0  1360368000   \n1                     0/0          5.0  1358467200   \n2                     0/0          1.0  1357084800   \n3                     0/0          5.0  1326240000   \n4                     1/1          5.0  1351987200   \n...                   ...          ...         ...   \n252051                0/0          5.0  1157155200   \n252052                1/1          5.0  1250467200   \n252053                0/0          5.0  1262476800   \n252054                6/6          2.0  1321228800   \n252055                0/1          5.0  1329177600   \n\n                                          review/summary  \\\n0                                           doesn't last   \n1                                         Smells divine.   \n2                                     Very disappointed!   \n3                                              Nice gift   \n4                               TRULY MADE A DIFFERENCE!   \n...                                                  ...   \n252051                ARTEC Kiwi Coloreflector shine wax   \n252052                                     A SWEET SCENT   \n252053                                       Luscious!!!   \n252054  This is the new formula- NOT vintage as pictured   \n252055                      Great value for the Scents!!   \n\n                                              review/text  \n0       very light scent that doesn't last very long. ...  \n1       This is my second bottle of sheer freesia, I j...  \n2       This perfume is just AWFUL! Smells nothing lik...  \n3       This was a gift for my sister. It wowed her. S...  \n4       I have been using this product for a couple ye...  \n...                                                   ...  \n252051  I have really enjoyed this product. It has a g...  \n252052  Since its founding in 1982 Thymes has won legi...  \n252053  I love love love this item!!! The scent is lik...  \n252054  Received the order very quickly but what arriv...  \n252055  Have been using this cologne since at least 19...  \n\n[252056 rows x 10 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"df['review/score'] = df['review/score'].astype(float).astype(int)\n\n\ntrain_df = df.sample(frac=0.8, random_state=42)\ntest_df = df.drop(train_df.index)\n\n\ntrain_texts = train_df['review/text'].tolist()\ntrain_labels = train_df['review/score'].astype(int) - 1  \n\ntrain_inputs = tokenizer(train_texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:53:05.356684Z","iopub.execute_input":"2024-05-27T07:53:05.357105Z","iopub.status.idle":"2024-05-27T07:55:32.059561Z","shell.execute_reply.started":"2024-05-27T07:53:05.357070Z","shell.execute_reply":"2024-05-27T07:55:32.058627Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_input_ids = train_inputs['input_ids'].cuda()\ntrain_attention_masks = train_inputs['attention_mask'].cuda()\ntrain_labels = torch.tensor(train_labels.values).cuda()\n\ntrain_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n\ntest_texts = test_df['review/text'].tolist()\ntest_labels = test_df['review/score'].astype(int) - 1  \n\ntest_inputs = tokenizer(test_texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n\ntest_input_ids = test_inputs['input_ids'].cuda()\ntest_attention_masks = test_inputs['attention_mask'].cuda()\ntest_labels = torch.tensor(test_labels.values).cuda()\n\ntest_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n\n\noptimizer = AdamW(model.parameters(), lr=2e-5)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:55:32.061877Z","iopub.execute_input":"2024-05-27T07:55:32.062607Z","iopub.status.idle":"2024-05-27T07:56:07.256177Z","shell.execute_reply.started":"2024-05-27T07:55:32.062572Z","shell.execute_reply":"2024-05-27T07:56:07.255214Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.profiler\nmodel.train()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nwith torch.profiler.profile(\n    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n    schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n    record_shapes=True,\n    profile_memory=True,\n    with_stack=True\n) as prof:\n    for epoch in range(1):\n        for batch in train_loader:\n            input_ids, attention_mask, labels = [t.to(device) for t in batch]\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            loss.backward()\n            prof.step()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:56:07.257454Z","iopub.execute_input":"2024-05-27T07:56:07.257758Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"STAGE:2024-05-27 07:56:08 34:34 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\nSTAGE:2024-05-27 07:56:10 34:34 ActivityProfilerController.cpp:318] Completed Stage: Collection\nSTAGE:2024-05-27 07:56:10 34:34 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\nSTAGE:2024-05-27 07:56:13 34:34 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\nSTAGE:2024-05-27 07:56:14 34:34 ActivityProfilerController.cpp:318] Completed Stage: Collection\nSTAGE:2024-05-27 07:56:14 34:34 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\npredictions, true_labels = [], []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids, attention_mask, labels = batch\n        \n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        \n        predictions.extend(torch.argmax(logits, dim=1).tolist())\n        true_labels.extend(labels.tolist())\n\n# Calculate metrics\naccuracy = accuracy_score(true_labels, predictions)\nf1 = f1_score(true_labels, predictions, average='weighted')\n\nprint(f'Accuracy: {accuracy}')\nprint(f'F1 Score: {f1}')\n\n# Calculate BLEU score\nbleu_scores = []\nfor ref, hyp in zip(test_texts, [test_texts[i] for i in predictions]):\n    bleu_scores.append(sentence_bleu([ref.split()], hyp.split()))\nbleu_score_avg = sum(bleu_scores) / len(bleu_scores)\n\nprint(f'BLEU Score: {bleu_score_avg}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}